{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d0a1bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = \"https://api.openai.com/v1\",\n",
    "    api_key = \"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\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccae873d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0/5045...\n",
      "Processing row 100/5045...\n",
      "Processing row 200/5045...\n",
      "Processing row 300/5045...\n",
      "Processing row 400/5045...\n",
      "Processing row 500/5045...\n",
      "Processing row 600/5045...\n",
      "Processing row 700/5045...\n",
      "Processing row 800/5045...\n",
      "Processing row 900/5045...\n",
      "Processing row 1000/5045...\n",
      "Processing row 1100/5045...\n",
      "Processing row 1200/5045...\n",
      "Processing row 1300/5045...\n",
      "Processing row 1400/5045...\n",
      "Processing row 1500/5045...\n",
      "Processing row 1600/5045...\n",
      "Processing row 1700/5045...\n",
      "Processing row 1800/5045...\n",
      "Processing row 1900/5045...\n",
      "Processing row 2000/5045...\n",
      "Processing row 2100/5045...\n",
      "Processing row 2200/5045...\n",
      "Processing row 2300/5045...\n",
      "Processing row 2400/5045...\n",
      "Processing row 2500/5045...\n",
      "Processing row 2600/5045...\n",
      "Processing row 2700/5045...\n",
      "Processing row 2800/5045...\n",
      "Processing row 2900/5045...\n",
      "Processing row 3000/5045...\n",
      "Processing row 3100/5045...\n",
      "Processing row 3200/5045...\n",
      "Processing row 3300/5045...\n",
      "Processing row 3400/5045...\n",
      "Processing row 3500/5045...\n",
      "Processing row 3600/5045...\n",
      "Processing row 3700/5045...\n",
      "Processing row 3800/5045...\n",
      "Processing row 3900/5045...\n",
      "Processing row 4000/5045...\n",
      "Processing row 4100/5045...\n",
      "Processing row 4200/5045...\n",
      "Processing row 4300/5045...\n",
      "Processing row 4400/5045...\n",
      "Processing row 4500/5045...\n",
      "Processing row 4600/5045...\n",
      "Processing row 4700/5045...\n",
      "Processing row 4800/5045...\n",
      "Processing row 4900/5045...\n",
      "Processing row 5000/5045...\n",
      "✅ Done! Saved to 'news_with_generated_headlines.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import time\n",
    "\n",
    "# === Load dataset ===\n",
    "df = pd.read_csv(\"./data/news_body.csv\")  # Must contain 'body' column\n",
    "df = df.dropna(subset=[\"body\"])  # Remove empty rows\n",
    "df[\"generated_headline\"] = \"\"\n",
    "\n",
    "# === Define function to get summary headline from LLM ===\n",
    "def get_headline_from_llm(news_body):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant. You write short, non-sarcastic news headlines like HuffPost.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"\"\"Here is a news article body:\\n\\n{news_body}\\n\\nSummarize this article into a short, informative, non-sarcastic news headline like a HuffPost headline.\"\"\",\n",
    "                },\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# === Generate headlines row by row ===\n",
    "for idx, row in df.iterrows():\n",
    "    if idx % 100 == 0:\n",
    "        print(f\"Processing row {idx}/{len(df)}...\")\n",
    "    summary_headline = get_headline_from_llm(row[\"body\"])\n",
    "    df.at[idx, \"generated_headline\"] = summary_headline\n",
    "    # time.sleep(1.2)  # Add a delay to respect OpenAI rate limits\n",
    "\n",
    "# === Save the updated dataset ===\n",
    "df.to_csv(\"news_with_generated_headlines.csv\", index=False)\n",
    "print(\"✅ Done! Saved to 'news_with_generated_headlines.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
